{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prospective-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compound-venezuela",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>year</th>\n",
       "      <th>violent_crime</th>\n",
       "      <th>murder</th>\n",
       "      <th>rape</th>\n",
       "      <th>robbery</th>\n",
       "      <th>aggravated_assault</th>\n",
       "      <th>property_crime</th>\n",
       "      <th>burglary</th>\n",
       "      <th>larceny_theft</th>\n",
       "      <th>...</th>\n",
       "      <th>frm_15</th>\n",
       "      <th>points_15</th>\n",
       "      <th>median_hh_income</th>\n",
       "      <th>median_hh_inc_moe</th>\n",
       "      <th>poverty_count</th>\n",
       "      <th>poverty_count_moe</th>\n",
       "      <th>poverty_rate</th>\n",
       "      <th>poverty_rate_moe</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atlantic</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.391731</td>\n",
       "      <td>0.475</td>\n",
       "      <td>62678</td>\n",
       "      <td>2822</td>\n",
       "      <td>29057</td>\n",
       "      <td>4251</td>\n",
       "      <td>1.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1</td>\n",
       "      <td>196067.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bergen</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>3.391731</td>\n",
       "      <td>0.475</td>\n",
       "      <td>107971</td>\n",
       "      <td>3025</td>\n",
       "      <td>52980</td>\n",
       "      <td>7662</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3</td>\n",
       "      <td>494018.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burlington</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.391731</td>\n",
       "      <td>0.475</td>\n",
       "      <td>88443</td>\n",
       "      <td>3233</td>\n",
       "      <td>24961</td>\n",
       "      <td>4374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5</td>\n",
       "      <td>238593.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Camden</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>3.391731</td>\n",
       "      <td>0.475</td>\n",
       "      <td>73168</td>\n",
       "      <td>2374</td>\n",
       "      <td>53641</td>\n",
       "      <td>7048</td>\n",
       "      <td>1.4</td>\n",
       "      <td>10.7</td>\n",
       "      <td>7</td>\n",
       "      <td>181980.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cape May</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.391731</td>\n",
       "      <td>0.475</td>\n",
       "      <td>66565</td>\n",
       "      <td>4753</td>\n",
       "      <td>8853</td>\n",
       "      <td>1981</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.8</td>\n",
       "      <td>9</td>\n",
       "      <td>389294.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       county  year  violent_crime  murder  rape  robbery  aggravated_assault  \\\n",
       "0    Atlantic  2019              0       0     0        0                   0   \n",
       "1      Bergen  2019              2       0     2        0                   0   \n",
       "2  Burlington  2019              0       0     0        0                   0   \n",
       "3      Camden  2019              2       0     0        0                   2   \n",
       "4    Cape May  2019              0       0     0        0                   0   \n",
       "\n",
       "   property_crime  burglary  larceny_theft  ...    frm_15  points_15  \\\n",
       "0               0         0              0  ...  3.391731      0.475   \n",
       "1              46         2             44  ...  3.391731      0.475   \n",
       "2               0         0              0  ...  3.391731      0.475   \n",
       "3              44         4             38  ...  3.391731      0.475   \n",
       "4               0         0              0  ...  3.391731      0.475   \n",
       "\n",
       "   median_hh_income  median_hh_inc_moe  poverty_count  poverty_count_moe  \\\n",
       "0             62678               2822          29057               4251   \n",
       "1            107971               3025          52980               7662   \n",
       "2             88443               3233          24961               4374   \n",
       "3             73168               2374          53641               7048   \n",
       "4             66565               4753           8853               1981   \n",
       "\n",
       "   poverty_rate  poverty_rate_moe  county_fips      price  \n",
       "0           1.6              11.3            1  196067.42  \n",
       "1           0.8               5.7            3  494018.42  \n",
       "2           1.0               5.7            5  238593.67  \n",
       "3           1.4              10.7            7  181980.75  \n",
       "4           2.2               9.8            9  389294.58  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  import csv\n",
    "df = pd.read_csv('../Resources/final_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "numerical-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  drop nulls\n",
    "df.dropna(how='any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "constant-milan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 22) (164,)\n"
     ]
    }
   ],
   "source": [
    "# Set features. This will also be used as x values.\n",
    "X = df.drop(['county', 'county_fips'], axis=1)\n",
    "y = df[\"county\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unauthorized-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing groups and scale data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "single-graduate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the data into model\n",
    "rfm = RandomForestClassifier(n_estimators=200)\n",
    "rfm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "persistent-simon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.9512195121951219\n"
     ]
    }
   ],
   "source": [
    "predictions = rfm.predict(X_test_scaled)\n",
    "base_train_accuracy = round(rfm.score(X_train_scaled, y_train)*100,3)\n",
    "base_test_accuracy = round(rfm.score(X_test_scaled, y_test)*100,3)\n",
    "print(f\"Training Data Score: {rfm.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {rfm.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e712594f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'violent_crime', 'murder', 'rape', 'robbery',\n",
       "       'aggravated_assault', 'property_crime', 'burglary', 'larceny_theft',\n",
       "       'motor_vehicle_theft', 'arson', 'frm_30', 'points_30', 'frm_15',\n",
       "       'points_15', 'median_hh_income', 'median_hh_inc_moe', 'poverty_count',\n",
       "       'poverty_count_moe', 'poverty_rate', 'poverty_rate_moe', 'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a53e3512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['violent_crime', 'murder', 'rape', 'robbery', 'aggravated_assault',\n",
       "       'property_crime', 'burglary', 'larceny_theft', 'motor_vehicle_theft',\n",
       "       'arson', 'frm_30', 'points_30', 'frm_15', 'points_15',\n",
       "       'median_hh_income', 'median_hh_inc_moe', 'poverty_count',\n",
       "       'poverty_count_moe', 'poverty_rate', 'poverty_rate_moe'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = X_test.drop(['year','price'],axis = 1)\n",
    "input_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2fc0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_case = [input_data['violent_crime'].min(), input_data['murder'].min(), input_data['rape'].min(),\n",
    "            input_data['robbery'].min(), input_data['aggravated_assault'].min(), input_data['property_crime'].min(),\n",
    "            input_data['burglary'].min(), input_data['larceny_theft'].min(), input_data['motor_vehicle_theft'].min(),\n",
    "            input_data['arson'].min(), input_data['frm_30'].min(), input_data['points_30'].min(),\n",
    "            input_data['frm_15'].min(), input_data['points_15'].min(), input_data['median_hh_income'].max(),input_data['median_hh_inc_moe'].min(),\n",
    "            input_data['poverty_count'].min(), input_data['poverty_count_moe'].min(), input_data['poverty_rate'].min(),\n",
    "            input_data['poverty_rate_moe'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "937b9426",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_case = [input_data['violent_crime'].max(), input_data['murder'].max(), input_data['rape'].max(),\n",
    "            input_data['robbery'].max(), input_data['aggravated_assault'].max(), input_data['property_crime'].max(),\n",
    "            input_data['burglary'].max(), input_data['larceny_theft'].max(), input_data['motor_vehicle_theft'].max(),\n",
    "            input_data['arson'].max(), input_data['frm_30'].max(), input_data['points_30'].max(),\n",
    "            input_data['frm_15'].max(), input_data['points_15'].max(), input_data['median_hh_income'].min(),\n",
    "           input_data['median_hh_inc_moe'].max(),\n",
    "            input_data['poverty_count'].max(), input_data['poverty_count_moe'].max(), input_data['poverty_rate'].max(),\n",
    "            input_data['poverty_rate_moe'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45a4aa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  violent_crime  murder  rape  robbery  aggravated_assault  \\\n",
      "0  2020              0       0     0        0                   0   \n",
      "\n",
      "   property_crime  burglary  larceny_theft  motor_vehicle_theft  ...  \\\n",
      "0               0         0              0                    0  ...   \n",
      "\n",
      "   points_30    frm_15  points_15  median_hh_income  median_hh_inc_moe  \\\n",
      "0   0.484615  2.930769       0.45            113083               1623   \n",
      "\n",
      "   poverty_count  poverty_count_moe  poverty_rate  poverty_rate_moe  \\\n",
      "0           4793                918           0.8               3.9   \n",
      "\n",
      "   county_fips  \n",
      "0            1  \n",
      "\n",
      "[1 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "test_array = pd.DataFrame({'year':2020,'violent_crime':input_data['violent_crime'].min(), 'murder':input_data['murder'].min(), 'rape':input_data['rape'].min(),\n",
    "            'robbery':input_data['robbery'].min(), 'aggravated_assault':input_data['aggravated_assault'].min(), 'property_crime': input_data['property_crime'].min(),\n",
    "            'burglary':input_data['burglary'].min(), 'larceny_theft':input_data['larceny_theft'].min(), 'motor_vehicle_theft':input_data['motor_vehicle_theft'].min(),\n",
    "            'arson':input_data['arson'].min(), 'frm_30':input_data['frm_30'].min(), 'points_30': input_data['points_30'].min(),\n",
    "           'frm_15':input_data['frm_15'].min(), 'points_15':input_data['points_15'].min(), 'median_hh_income': input_data['median_hh_income'].max(),'median_hh_inc_moe':input_data['median_hh_inc_moe'].min(),\n",
    "           'poverty_count': input_data['poverty_count'].min(),'poverty_count_moe': input_data['poverty_count_moe'].min(), 'poverty_rate':input_data['poverty_rate'].min(),\n",
    "            'poverty_rate_moe':input_data['poverty_rate_moe'].min(),'county_fips':1},[0])\n",
    "print(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "retired-apparatus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Atlantic       1.00      1.00      1.00         2\n",
      "      Bergen       1.00      1.00      1.00         1\n",
      "  Burlington       1.00      1.00      1.00         2\n",
      "      Camden       1.00      0.50      0.67         2\n",
      "    Cape May       1.00      1.00      1.00         1\n",
      "  Cumberland       1.00      1.00      1.00         4\n",
      "       Essex       1.00      1.00      1.00         1\n",
      "  Gloucester       1.00      1.00      1.00         1\n",
      "      Hudson       1.00      1.00      1.00         3\n",
      "   Hunterdon       1.00      1.00      1.00         1\n",
      "      Mercer       1.00      1.00      1.00         2\n",
      "   Middlesex       1.00      1.00      1.00         4\n",
      "    Monmouth       1.00      1.00      1.00         2\n",
      "      Morris       1.00      1.00      1.00         2\n",
      "       Ocean       0.67      0.67      0.67         3\n",
      "     Passaic       1.00      1.00      1.00         2\n",
      "       Salem       1.00      1.00      1.00         1\n",
      "      Sussex       1.00      1.00      1.00         2\n",
      "       Union       0.80      1.00      0.89         4\n",
      "      Warren       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.95        41\n",
      "   macro avg       0.97      0.96      0.96        41\n",
      "weighted avg       0.96      0.95      0.95        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-exhibit",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ranking-window",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 200,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get randomforest params\n",
    "rfm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pleased-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 600, 1200, 1400],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "grid = GridSearchCV(rfm, param_grid, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "increasing-terrain",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danbzanoria/opt/miniconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END criterion=gini, max_features=auto, n_estimators=200; total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_features=auto, n_estimators=200; total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_features=auto, n_estimators=200; total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_features=auto, n_estimators=200; total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_features=auto, n_estimators=200; total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_features=auto, n_estimators=600; total time=   0.5s\n",
      "[CV 2/5] END criterion=gini, max_features=auto, n_estimators=600; total time=   0.5s\n",
      "[CV 3/5] END criterion=gini, max_features=auto, n_estimators=600; total time=   0.5s\n",
      "[CV 4/5] END criterion=gini, max_features=auto, n_estimators=600; total time=   0.5s\n",
      "[CV 5/5] END criterion=gini, max_features=auto, n_estimators=600; total time=   0.5s\n",
      "[CV 1/5] END criterion=gini, max_features=auto, n_estimators=1200; total time=   0.9s\n",
      "[CV 2/5] END criterion=gini, max_features=auto, n_estimators=1200; total time=   0.9s\n",
      "[CV 3/5] END criterion=gini, max_features=auto, n_estimators=1200; total time=   0.9s\n",
      "[CV 4/5] END criterion=gini, max_features=auto, n_estimators=1200; total time=   0.9s\n",
      "[CV 5/5] END criterion=gini, max_features=auto, n_estimators=1200; total time=   1.0s\n",
      "[CV 1/5] END criterion=gini, max_features=auto, n_estimators=1400; total time=   1.1s\n",
      "[CV 2/5] END criterion=gini, max_features=auto, n_estimators=1400; total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_features=auto, n_estimators=1400; total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_features=auto, n_estimators=1400; total time=   1.1s\n",
      "[CV 5/5] END criterion=gini, max_features=auto, n_estimators=1400; total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, n_estimators=200; total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, n_estimators=200; total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, n_estimators=200; total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, n_estimators=200; total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, n_estimators=200; total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, n_estimators=600; total time=   0.5s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, n_estimators=600; total time=   0.5s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, n_estimators=600; total time=   0.5s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, n_estimators=600; total time=   0.5s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, n_estimators=600; total time=   0.5s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, n_estimators=1200; total time=   1.0s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, n_estimators=1200; total time=   1.0s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, n_estimators=1200; total time=   1.0s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, n_estimators=1200; total time=   0.9s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, n_estimators=1200; total time=   1.0s\n",
      "[CV 1/5] END criterion=gini, max_features=sqrt, n_estimators=1400; total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_features=sqrt, n_estimators=1400; total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_features=sqrt, n_estimators=1400; total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_features=sqrt, n_estimators=1400; total time=   1.1s\n",
      "[CV 5/5] END criterion=gini, max_features=sqrt, n_estimators=1400; total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, n_estimators=200; total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, n_estimators=200; total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, n_estimators=200; total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, n_estimators=200; total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, n_estimators=200; total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, n_estimators=600; total time=   0.5s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, n_estimators=600; total time=   0.5s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, n_estimators=600; total time=   0.5s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, n_estimators=600; total time=   0.5s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, n_estimators=600; total time=   0.5s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, n_estimators=1200; total time=   1.0s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, n_estimators=1200; total time=   1.0s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, n_estimators=1200; total time=   0.9s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, n_estimators=1200; total time=   0.9s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, n_estimators=1200; total time=   0.9s\n",
      "[CV 1/5] END criterion=gini, max_features=log2, n_estimators=1400; total time=   1.1s\n",
      "[CV 2/5] END criterion=gini, max_features=log2, n_estimators=1400; total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_features=log2, n_estimators=1400; total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_features=log2, n_estimators=1400; total time=   1.1s\n",
      "[CV 5/5] END criterion=gini, max_features=log2, n_estimators=1400; total time=   1.1s\n",
      "[CV 1/5] END criterion=entropy, max_features=auto, n_estimators=200; total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_features=auto, n_estimators=200; total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_features=auto, n_estimators=200; total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_features=auto, n_estimators=200; total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_features=auto, n_estimators=200; total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_features=auto, n_estimators=600; total time=   0.5s\n",
      "[CV 2/5] END criterion=entropy, max_features=auto, n_estimators=600; total time=   0.5s\n",
      "[CV 3/5] END criterion=entropy, max_features=auto, n_estimators=600; total time=   0.5s\n",
      "[CV 4/5] END criterion=entropy, max_features=auto, n_estimators=600; total time=   0.5s\n",
      "[CV 5/5] END criterion=entropy, max_features=auto, n_estimators=600; total time=   0.5s\n",
      "[CV 1/5] END criterion=entropy, max_features=auto, n_estimators=1200; total time=   1.0s\n",
      "[CV 2/5] END criterion=entropy, max_features=auto, n_estimators=1200; total time=   1.0s\n",
      "[CV 3/5] END criterion=entropy, max_features=auto, n_estimators=1200; total time=   1.0s\n",
      "[CV 4/5] END criterion=entropy, max_features=auto, n_estimators=1200; total time=   1.0s\n",
      "[CV 5/5] END criterion=entropy, max_features=auto, n_estimators=1200; total time=   1.1s\n",
      "[CV 1/5] END criterion=entropy, max_features=auto, n_estimators=1400; total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_features=auto, n_estimators=1400; total time=   1.2s\n",
      "[CV 3/5] END criterion=entropy, max_features=auto, n_estimators=1400; total time=   1.3s\n",
      "[CV 4/5] END criterion=entropy, max_features=auto, n_estimators=1400; total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_features=auto, n_estimators=1400; total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, n_estimators=200; total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, n_estimators=200; total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, n_estimators=200; total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, n_estimators=200; total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, n_estimators=200; total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, n_estimators=600; total time=   0.5s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, n_estimators=600; total time=   0.6s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, n_estimators=600; total time=   0.5s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, n_estimators=600; total time=   0.5s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, n_estimators=600; total time=   0.6s\n",
      "[CV 1/5] END criterion=entropy, max_features=sqrt, n_estimators=1200; total time=   1.0s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, n_estimators=1200; total time=   1.0s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, n_estimators=1200; total time=   1.1s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, n_estimators=1200; total time=   1.1s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, n_estimators=1200; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END criterion=entropy, max_features=sqrt, n_estimators=1400; total time=   1.2s\n",
      "[CV 2/5] END criterion=entropy, max_features=sqrt, n_estimators=1400; total time=   1.2s\n",
      "[CV 3/5] END criterion=entropy, max_features=sqrt, n_estimators=1400; total time=   1.3s\n",
      "[CV 4/5] END criterion=entropy, max_features=sqrt, n_estimators=1400; total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_features=sqrt, n_estimators=1400; total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, n_estimators=200; total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, n_estimators=200; total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, n_estimators=200; total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, n_estimators=200; total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, n_estimators=200; total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, n_estimators=600; total time=   0.5s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, n_estimators=600; total time=   0.5s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, n_estimators=600; total time=   0.5s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, n_estimators=600; total time=   0.5s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, n_estimators=600; total time=   0.5s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, n_estimators=1200; total time=   1.0s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, n_estimators=1200; total time=   1.1s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, n_estimators=1200; total time=   1.1s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, n_estimators=1200; total time=   1.0s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, n_estimators=1200; total time=   1.0s\n",
      "[CV 1/5] END criterion=entropy, max_features=log2, n_estimators=1400; total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_features=log2, n_estimators=1400; total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_features=log2, n_estimators=1400; total time=   1.2s\n",
      "[CV 4/5] END criterion=entropy, max_features=log2, n_estimators=1400; total time=   1.2s\n",
      "[CV 5/5] END criterion=entropy, max_features=log2, n_estimators=1400; total time=   1.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(n_estimators=200),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [200, 600, 1200, 1400]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "extensive-writer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_features': 'auto', 'n_estimators': 1200}\n",
      "0.976\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "improved-timber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=600)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfm = RandomForestClassifier(n_estimators=600,criterion= 'gini', max_features= 'auto' )\n",
    "rfm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "relevant-mobile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.926829268292683\n"
     ]
    }
   ],
   "source": [
    "predictions = rfm.predict(X_test_scaled)\n",
    "tuned_train_accuracy = round(rfm.score(X_train_scaled, y_train)*100,3)\n",
    "tuned_test_accuracy = round(rfm.score(X_test_scaled, y_test)*100,3)\n",
    "print(f\"Training Data Score: {rfm.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {rfm.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "operating-punishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Atlantic       1.00      1.00      1.00         2\n",
      "      Bergen       1.00      1.00      1.00         1\n",
      "  Burlington       1.00      1.00      1.00         2\n",
      "      Camden       1.00      0.50      0.67         2\n",
      "    Cape May       1.00      1.00      1.00         1\n",
      "  Cumberland       1.00      1.00      1.00         4\n",
      "       Essex       1.00      1.00      1.00         1\n",
      "  Gloucester       1.00      1.00      1.00         1\n",
      "      Hudson       1.00      1.00      1.00         3\n",
      "   Hunterdon       1.00      1.00      1.00         1\n",
      "      Mercer       1.00      1.00      1.00         2\n",
      "   Middlesex       1.00      1.00      1.00         4\n",
      "    Monmouth       0.67      1.00      0.80         2\n",
      "      Morris       1.00      1.00      1.00         2\n",
      "       Ocean       0.67      0.67      0.67         3\n",
      "     Passaic       1.00      1.00      1.00         2\n",
      "       Salem       1.00      1.00      1.00         1\n",
      "      Sussex       1.00      1.00      1.00         2\n",
      "       Union       0.75      0.75      0.75         4\n",
      "      Warren       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.93        41\n",
      "   macro avg       0.95      0.95      0.94        41\n",
      "weighted avg       0.93      0.93      0.93        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "athletic-contribution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/NJ_rfm.sav']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  save the model\n",
    "filename = '../Models/NJ_rfm.sav'\n",
    "joblib.dump(grid, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-health",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "packed-designation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Base Train Model</th>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Base Test Model</th>\n",
       "      <td>95.122%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned Train Model</th>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned Test Model</th>\n",
       "      <td>92.683%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RF Accuracy\n",
       "                             \n",
       "Base Train Model       100.0%\n",
       "Base Test Model       95.122%\n",
       "Tuned Train Model      100.0%\n",
       "Tuned Test Model      92.683%"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations = {'': ['Base Train Model', 'Base Test Model', 'Tuned Train Model', 'Tuned Test Model'],\n",
    "               'RF Accuracy': [f\"{base_train_accuracy}%\", f\"{base_test_accuracy}%\", f\"{tuned_train_accuracy}%\", f\"{tuned_test_accuracy}%\"]}\n",
    "\n",
    "evaluations_df = pd.DataFrame(evaluations)\n",
    "evaluations_df = evaluations_df.set_index('')\n",
    "\n",
    "evaluations_df.to_csv('../Resources/RFM_eval.csv')\n",
    "evaluations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-package",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-vertex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-dependence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv] *",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
